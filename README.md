# Second-Person
# Interactive Face Mesh Reality
## Real-Time Computer Vision Art Installation

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-green.svg)](https://opencv.org/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-Latest-orange.svg)](https://mediapipe.dev/)

###  Project Vision

Interactive Face Mesh Reality is a real-time computer vision art installation that creates an immersive augmented reality experience by combining face tracking, image manipulation, and visual effects. The system tracks facial movements to create dynamic interactions between the user and a reference artwork, featuring polygon masking, delayed movement effects, and abstract visualization overlays.

### Key Features

- **Real-Time Face Tracking**: Advanced MediaPipe face mesh detection with 468 landmark points
- **Interactive Polygon Masking**: User-selectable regions that respond to facial movements
- **Delayed Movement Effects**: Time-delayed visual feedback creating ghosting and trail effects
- **Abstract Visualization**: Multi-layered image processing including pixelation, edge detection, and color manipulation
- **Dual View System**: Split-screen display with main artwork and abstract viewer
- **Dynamic Blending**: Seamless integration of live camera feed with static reference imagery

## Quick Start

### Prerequisites
- Python 3.8 or higher
- Webcam or camera device
- Reference image file(s)

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/CJD-11/Second-Person

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application:**
   ```bash
   python src/second_person.py
   ```

### Basic Usage

1. **Setup Reference Image:**
   - Place your reference image in the `assets/` folder
   - Update the image path in the configuration

2. **Polygon Selection:**
   - Left-click to add polygon vertices
   - Right-click to complete polygon selection (minimum 3 points)
   - Press 'q' to exit polygon selection mode

3. **Real-Time Interaction:**
   - Position your face in the camera view
   - Watch as the selected polygon region responds to your movements
   - Press 'q' to exit the application


##  Core Features

### Face Tracking System
- **468-point face mesh** detection using MediaPipe
- **Real-time landmark tracking** with sub-pixel accuracy
- **Robust detection** across varying lighting conditions
- **Movement queue system** for smooth delayed effects

### Visual Effects Pipeline
- **Polygon Masking**: Dynamic region selection and manipulation
- **Movement Amplification**: Configurable sensitivity and delay parameters
- **Abstract Visualization**: Multi-stage image processing pipeline
- **Segmentation Blending**: Seamless person extraction and overlay

### Image Processing Effects
- **Pixelation**: Adjustable pixel size for retro aesthetic
- **Edge Detection**: Canny edge highlighting with color enhancement
- **Color Noise**: Controlled random color variation
- **Channel Separation**: RGB channel blur effects
- **Grayscale Conversion**: Selective desaturation

## ‚öôÔ∏è Configuration

### Basic Configuration
```python
# config.py
CAMERA_INDEX = 0
REFERENCE_IMAGE_PATH = "assets/sample_reference.jpg"
STANDARD_WINDOW_SIZE = (900, 1200)
MOVEMENT_DELAY = 1.0  # seconds
MOVEMENT_AMPLIFICATION = 2.0
```

### Advanced Settings
```python
# Face detection parameters
FACE_DETECTION_CONFIDENCE = 0.5
FACE_TRACKING_CONFIDENCE = 0.5

# Visual effects parameters
PIXEL_SIZE = 12
EDGE_THRESHOLD_LOW = 50
EDGE_THRESHOLD_HIGH = 150
COLOR_NOISE_INTENSITY = 20
BLUR_KERNEL_SIZE = (11, 11)
```

##  Technical Architecture

### Core Components

**Face Tracking Module**
```python
class FaceTracker:
    def __init__(self, confidence=0.5):
        self.face_mesh = mp.solutions.face_mesh.FaceMesh(
            min_detection_confidence=confidence
        )
    
    def track_landmarks(self, frame):
        # Returns 468 facial landmarks
        pass
```

**Image Processor**
```python
class ImageProcessor:
    def apply_pixelation(self, image, pixel_size):
        # Pixelation effect implementation
        pass
    
    def apply_edge_enhancement(self, image):
        # Edge detection and highlighting
        pass
```

**Polygon Selector**
```python
class PolygonSelector:
    def __init__(self, image):
        self.reference_image = image
        self.polygon_points = []
    
    def select_interactive(self):
        # Interactive polygon selection
        pass
```

### Processing Pipeline

1. **Input Capture**: Webcam frame acquisition and preprocessing
2. **Face Detection**: MediaPipe face mesh landmark extraction
3. **Movement Analysis**: Nose position tracking and delay queue management
4. **Polygon Manipulation**: Dynamic region transformation based on movement
5. **Effect Application**: Multi-stage visual effects processing
6. **Composition**: Layer blending and final image composition
7. **Display**: Real-time output rendering

## Performance Specifications

| Metric | Value | Notes |
|--------|-------|-------|
| **Frame Rate** | 30-60 FPS | Depends on hardware and effects |
| **Latency** | <50ms | Real-time interaction threshold |
| **Memory Usage** | ~200-500MB | Varies with image resolution |
| **CPU Usage** | 20-40% | Single core utilization |
| **Resolution Support** | Up to 1920x1080 | Configurable window sizes |
| **Face Detection** | 468 landmarks | MediaPipe face mesh |

## Artistic Applications

### Installation Art
- **Interactive Museums**: Visitor engagement with artwork
- **Gallery Exhibitions**: Dynamic art-audience interaction
- **Performance Art**: Real-time visual accompaniment
- **Digital Installations**: Immersive experience creation

### Creative Projects
- **Music Videos**: Synchronized visual effects
- **Live Streaming**: Enhanced broadcast content
- **Digital Art**: Generative visual creation
- **Educational Tools**: Computer vision demonstration


##  Advanced Usage

### Custom Effect Development
```python
from src.image_processor import ImageProcessor

class CustomProcessor(ImageProcessor):
    def apply_custom_effect(self, image):
        # Implement your own visual effect
        processed = self.apply_color_shift(image)
        processed = self.apply_distortion(processed)
        return processed
```

### Multi-Camera Setup
```python
# Support for multiple camera inputs
cameras = [
    cv2.VideoCapture(0),  # Primary camera
    cv2.VideoCapture(1),  # Secondary camera
]
```

### Real-Time Parameter Control
```python
# Dynamic parameter adjustment during runtime
keyboard_controls = {
    'p': increase_pixelation,
    'e': toggle_edge_detection,
    'n': adjust_noise_level,
    'd': change_delay_time
}
```

## Dependencies

### Core Libraries
- **OpenCV 4.5+**: Computer vision and image processing
- **MediaPipe**: Face detection and tracking
- **NumPy**: Numerical operations and array processing
- **Python 3.8+**: Core runtime environment

### Optional Libraries
- **PyQt5/Tkinter**: GUI enhancements
- **Pillow**: Additional image format support
- **SciPy**: Advanced mathematical operations
- **Matplotlib**: Visualization and debugging tools

##  Installation Options

### Standard Installation
```bash
pip install opencv-python mediapipe numpy
```

### Development Installation
```bash
git clone https://github.com/YOUR_USERNAME/interactive-face-mesh-reality.git
cd interactive-face-mesh-reality
pip install -e .
```

### Docker Installation
```bash
docker build -t face-mesh-reality .
docker run -it --device=/dev/video0 face-mesh-reality
```


## Contact

- **GitHub**: https://github.com/CJD-11
- **Email**: coreydziadzio@c11visualarts.com
- **Project Link**: https://github.com/CJD-11/Second-Person

## üìä Project Status

- ‚úÖ **Core Functionality**: Complete and functional
- ‚úÖ **Face Tracking**: Real-time 468-point detection
- ‚úÖ **Visual Effects**: Multi-layer processing pipeline
- üîÑ **Performance Optimization**: Ongoing improvements
- üìã **Mobile Support**: Future development
- üìã **VR/AR Integration**: Research phase

